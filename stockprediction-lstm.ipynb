{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q91fSnZuQgn2",
        "outputId": "94a1568b-de68-40ea-9f6f-a705268194ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install backtesting"
      ],
      "metadata": {
        "id": "8R6JWeuGRI4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import backtesting as bt\n",
        "from backtesting import Backtest, Strategy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# set cpu or gpu enabled device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVF3UKTFRQlz",
        "outputId": "3525be5b-146b-4b0c-aa2f-c0433cfee376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/backtesting/_plotting.py:50: UserWarning: Jupyter Notebook detected. Setting Bokeh output to notebook. This may not work in Jupyter clients without JavaScript support (e.g. PyCharm, Spyder IDE). Reset with `backtesting.set_bokeh_output(notebook=False)`.\n",
            "  warnings.warn('Jupyter Notebook detected. '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class cfg_LSTM1d:\n",
        "  # Configuration parameters for the LSTM model trained on 1D data\n",
        "  # Includes settings for data split, sequence length, learning rate, number of epochs,\n",
        "  # file paths, feature and target column names, LSTM settings (input size, hidden size, number of layers), and model save path\n",
        "\n",
        "  split_fraction = 0.85\n",
        "  time_steps = 5 # number of predictor timesteps\n",
        "  horizon = 1 # number of timesteps to be predicted\n",
        "  sequence_length = time_steps + horizon # determine sequence length\n",
        "  learning_rate=0.01\n",
        "  num_epochs=2000\n",
        "  path = '/content/drive/MyDrive/stock predict/technical/1D_technical.csv'\n",
        "  features = ['close']\n",
        "  target = 'close'\n",
        "  input_size = len(features)\n",
        "  hidden_size = 50\n",
        "  output_size = 1\n",
        "  numlayers = 2\n",
        "  save_path = '/content/drive/MyDrive/stock predict/pred_close1d.pt'\n",
        "  cols = ['open', 'high', 'low', 'close', 'rsi']\n",
        "\n",
        "class cfg_30m:\n",
        "  split_fraction = 1\n",
        "  time_steps = 5 # number of predictor timesteps\n",
        "  horizon = 1 # number of timesteps to be predicted\n",
        "  sequence_length = time_steps + horizon # determine sequence length\n",
        "  learning_rate=0.01\n",
        "  num_epochs=5000\n",
        "  path = '/content/drive/MyDrive/stock predict/30_min.csv'\n",
        "  features = ['close']\n",
        "  target = 'close'\n",
        "  input_size = len(features)\n",
        "  hidden_size = 50\n",
        "  output_size = 1\n",
        "  numlayers = 2\n",
        "  save_path = '/content/drive/MyDrive/stock predict/pred_30m.pt'\n",
        "\n",
        "class cfg_stack:\n",
        "  learning_rate=0.001\n",
        "  num_epochs=2000\n",
        "  save_path = '/content/drive/MyDrive/stock predict/pred_stacked.pt'\n",
        "  val_length = 0\n",
        "\n",
        "def load_data(path, features, type):\n",
        "  data_raw = pd.read_csv(path)\n",
        "  data_raw.columns = data_raw.columns.str.replace(' ', '')\n",
        "  data_raw['time'] = pd.to_datetime(data_raw['time'])\n",
        "  data_raw['time'] = data_raw['time'].dt.date\n",
        "  if type == '1d':\n",
        "    data_raw.set_index('time', inplace=True)\n",
        "  df = data_raw[features].copy()\n",
        "  return df, data_raw\n",
        "\n",
        "def splitrow(df, split_fraction):\n",
        "  return int(df.shape[0] * split_fraction)\n",
        "\n",
        "def trainvalidsplit(df, split_row):\n",
        "  train = df.iloc[:split_row].copy()\n",
        "  valid = df.iloc[split_row:].copy()\n",
        "  return train, valid\n",
        "\n",
        "def create_sequences(df, seq_length = cfg_LSTM1d.sequence_length):\n",
        "    df = df.values  # Convert DataFrame to numpy array\n",
        "\n",
        "    n = df.shape[0]\n",
        "    xs = np.zeros((n - seq_length, seq_length, df.shape[1]))\n",
        "    ys = np.zeros((n - seq_length, 1))\n",
        "\n",
        "    for i in range(n - seq_length):\n",
        "        xs[i] = df[i:(i+seq_length)]\n",
        "        ys[i] = df[i+seq_length, -1]  # predict the 'return' column one step ahead\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X = torch.from_numpy(xs)\n",
        "    y = torch.from_numpy(ys)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "class LSTM1d(nn.Module):\n",
        "    def __init__(self, input_size = cfg_LSTM1d.input_size, hidden_size = cfg_LSTM1d.hidden_size,\n",
        "                 num_layers = cfg_LSTM1d.numlayers, output_size=cfg_LSTM1d.output_size):\n",
        "\n",
        "      super(LSTM1d, self).__init__()\n",
        "\n",
        "      self.hidden_size = hidden_size\n",
        "      self.num_layers = num_layers\n",
        "      self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout = 0.2)\n",
        "      self.fc1 = nn.Linear(hidden_size, output_size)\n",
        "      #self.fc2 = nn.Linear(10, output_size)  # Add a second layer\n",
        "      self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "      h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "      c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "      h0.requires_grad = True\n",
        "      c0.requires_grad = True\n",
        "      out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "      out = self.tanh(self.fc1(out[:, -1, :]))  # apply tanh activation function to the output of the first linear layer\n",
        "      #out = self.fc2(out)  # pass through the second linear layer\n",
        "      return out\n",
        "\n",
        "\n",
        "class Stacking(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stacking, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 2)\n",
        "        self.fc2 = nn.Linear(2, 1)\n",
        "\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.tanh(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_fn(model, train, train_target,\n",
        "          learning_rate, num_epochs, save_path, type, valid = None,\n",
        "          valid_target = None):\n",
        "\n",
        "  criterion = torch.nn.MSELoss(reduction='mean')\n",
        "  optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  train = train.float().to(device)  # Convert to float\n",
        "  train_target = train_target.float().to(device)  # Convert to float\n",
        "\n",
        "  if type in ['1d']:\n",
        "    valid = valid.float().to(device)  # Convert to float\n",
        "    valid_target = valid_target.float().to(device)  # Convert to float\n",
        "\n",
        "    best_loss = float('inf')\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    y_train_pred = model(train)\n",
        "\n",
        "    print(y_train_pred.shape)\n",
        "    train_loss = criterion(y_train_pred, train_target)\n",
        "    optimiser.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "    if type in ['1d']:\n",
        "      model.eval()\n",
        "      outputs = model(valid)\n",
        "      val_loss = criterion(outputs, valid_target)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
        "              f'Train Loss: {train_loss.item():.4f}, ')\n",
        "\n",
        "    if type in ['1d']:\n",
        "      print(f'Validation Loss: {val_loss.item():.4f}')\n",
        "\n",
        "      if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model, save_path)\n",
        "    else: torch.save(model, save_path)\n",
        "\n",
        "\n",
        "def createpreds(model_path, t_scaler, sequences, device = device ):\n",
        "  model = torch.load(model_path)\n",
        "  model = model.to(device)\n",
        "  model.eval()\n",
        "  sequences = sequences.float().to(device) # Convert to float\n",
        "\n",
        "  preds = model(sequences)\n",
        "  preds = pd.DataFrame(t_scaler.inverse_transform(preds.detach().cpu().numpy()))\n",
        "  return preds\n",
        "\n",
        "def create_fulldf(data_raw, preds , cols, startrow):\n",
        "  bt_df = data_raw[cols].copy()\n",
        "  bt_df = bt_df[startrow:]\n",
        "  bt_df['predictions_1d'] = preds.values\n",
        "  return bt_df\n",
        "\n",
        "def plotpred(df, actual, pred, length):\n",
        "  plt.figure(figsize=(20,8))\n",
        "  plt.title('Price vs Prediction')\n",
        "  plt.plot(df[len(df)-length:][actual], color = 'blue', label = 'Actual Close Price')\n",
        "  plt.plot(df[len(df)-length:][pred], color = 'red', label = 'Predicted Close Price')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "bGnWvgmdR2I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_scaler1d = MinMaxScaler(feature_range=(-1, 1))\n",
        "t_scaler30m = MinMaxScaler(feature_range=(-1, 1))\n",
        "t_scaler_comb = MinMaxScaler(feature_range=(-1, 1))\n",
        "f_scaler1d = MinMaxScaler(feature_range=(-1, 1))\n",
        "f_scalercomb = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "#LSTM 1d model\n",
        "\n",
        "df_1d, data_1draw = load_data(path = cfg_LSTM1d.path, features = cfg_LSTM1d.features, type = '1d')\n",
        "split_row1d = splitrow(df_1d, split_fraction = cfg_LSTM1d.split_fraction)\n",
        "train_1d, valid_1d = trainvalidsplit(df_1d, split_row = split_row1d)\n",
        "\n",
        "train1d_scaled = train_1d.copy()\n",
        "valid1d_scaled = valid_1d.copy()\n",
        "train1d_scaled[cfg_LSTM1d.target] = t_scaler1d.fit_transform(train_1d[cfg_LSTM1d.target].values.reshape(-1,1))\n",
        "valid1d_scaled[cfg_LSTM1d.target] = t_scaler1d.fit_transform(valid_1d[cfg_LSTM1d.target].values.reshape(-1,1))\n",
        "\n",
        "train_sequences1d, train_target1d = create_sequences(df = train1d_scaled, seq_length = cfg_LSTM1d.sequence_length)\n",
        "valid_sequences1d, valid_target1d = create_sequences(df = valid1d_scaled, seq_length = cfg_LSTM1d.sequence_length)\n",
        "\n",
        "model1d = LSTM1d()\n",
        "model1d = model1d.to(device)\n",
        "\n",
        "train_fn(model = model1d, train = train_sequences1d, train_target = train_target1d, valid = valid_sequences1d,\n",
        "         valid_target = valid_target1d, learning_rate = cfg_LSTM1d.learning_rate,\n",
        "         num_epochs = cfg_LSTM1d.num_epochs, save_path = cfg_LSTM1d.save_path, type = '1d')\n",
        "\n",
        "pred1d = createpreds(model_path = cfg_LSTM1d.save_path, t_scaler = t_scaler1d,\n",
        "                     sequences = valid_sequences1d, device = device )\n",
        "\n",
        "bt_df = create_fulldf(data_raw = data_1draw, preds = pred1d, cols = cfg_LSTM1d.cols,\n",
        "                      startrow = split_row1d + cfg_LSTM1d.sequence_length)\n",
        "\n",
        "plotpred(df = bt_df, actual = 'close', pred = 'predictions_1d', length = 300)\n",
        "\n",
        "\n",
        "#LSTM 30m model\n",
        "\n",
        "df_30m, data_30mraw = load_data(path = cfg_30m.path, features = cfg_30m.features, type = '30m')\n",
        "\n",
        "split_row30m = splitrow(df_30m, split_fraction =cfg_30m.split_fraction)\n",
        "train_30m, valid_30m = trainvalidsplit(df_30m, split_row = split_row30m)\n",
        "\n",
        "train30_scaled = train_30m.copy()\n",
        "valid30_scaled = valid_30m.copy()\n",
        "\n",
        "train30_scaled[cfg_30m.target] = t_scaler30m.fit_transform(train30_scaled[cfg_30m.target].values.reshape(-1,1))\n",
        "train_sequences30m, train_target30m = create_sequences(df = train30_scaled, seq_length = cfg_30m.sequence_length)\n",
        "\n",
        "if not valid30_scaled.empty:\n",
        "  valid30_scaled[cfg_30m.target] = t_scaler30m.fit_transform(valid30_scaled[cfg_30m.target].values.reshape(-1,1))\n",
        "  valid_sequences30m, valid_target30m = create_sequences(df = valid30_scaled, seq_length = cfg_30m.sequence_length)\n",
        "\n",
        "\n",
        "model30m = LSTM1d()\n",
        "model30m = model30m.to(device)\n",
        "\n",
        "train_fn(model = model30m, train = train_sequences30m, train_target = train_target30m,\n",
        "          learning_rate = cfg_30m.learning_rate,\n",
        "         num_epochs = cfg_30m.num_epochs, save_path = cfg_30m.save_path, type = '30m')\n",
        "\n",
        "pred30m = createpreds(model_path = cfg_30m.save_path, t_scaler = t_scaler30m,\n",
        "                     sequences = train_sequences30m, device = device )\n",
        "\n",
        "df_30m = data_30mraw[cfg_30m.sequence_length:].copy()\n",
        "df_30m['pred_30'] = pred30m.values\n",
        "\n",
        "plotpred(df = df_30m, actual = 'close', pred = 'pred_30', length = 300)\n",
        "\n",
        "df_30m = df_30m[df_30m['time'] != df_30m['time'].shift()]\n",
        "\n",
        "df_comb = bt_df.merge(df_30m[['time', 'pred_30']], on='time', how = 'inner')\n",
        "\n",
        "#######stacking\n",
        "\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_comb = df_comb[['predictions_1d', 'pred_30']].copy()\n",
        "#val_comb = df_comb[['predictions_1d', 'pred_30']][-cfg_stack.val_length:]\n",
        "\n",
        "traincomb_target = df_comb[['close']].copy()\n",
        "#valcomb_target = df_comb[['close']][-100:]\n",
        "\n",
        "train_comb_scaled = f_scalercomb.fit_transform(train_comb)\n",
        "#val_comb_scaled = f_scalercomb.transform(val_comb)\n",
        "\n",
        "traincomb_target_scaled = t_scaler_comb.fit_transform(traincomb_target.values.reshape(-1,1))\n",
        "#valcomb_target_scaled = t_scaler_comb.transform(valcomb_target.values.reshape(-1,1))\n",
        "\n",
        "# Convert features and target to tensors\n",
        "train_features_tensor = torch.tensor(train_comb_scaled, dtype=torch.float32)\n",
        "train_target_tensor = torch.tensor(traincomb_target_scaled, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "#val_features_tensor = torch.tensor(val_comb_scaled, dtype=torch.float32)\n",
        "#val_target_tensor = torch.tensor(valcomb_target_scaled, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "\n",
        "comb_model = Stacking()\n",
        "comb_model = comb_model.to(device)\n",
        "\n",
        "train_fn(model = comb_model, train = train_features_tensor, train_target = train_target_tensor,\n",
        "         #valid = val_features_tensor, valid_target = val_target_tensor,\n",
        "          learning_rate = cfg_stack.learning_rate,\n",
        "         num_epochs = cfg_stack.num_epochs, save_path = cfg_stack.save_path, type = 'stack')\n",
        "\n",
        "predfinal = createpreds(model_path = cfg_stack.save_path, t_scaler = t_scaler_comb,\n",
        "                     sequences = train_features_tensor, device = device )\n",
        "\n",
        "###Backtesting\n",
        "\n",
        "backtest = df_comb[-300:].copy()\n",
        "backtest['predictions_final'] = predfinal[-300:].values\n",
        "backtest = backtest.reset_index(drop=True)\n",
        "\n",
        "threshold = 0\n",
        "backtest['predictions_final'] = backtest['predictions_final'].shift(-1)\n",
        "backtest['Signal'] = 0\n",
        "backtest.loc[backtest['predictions_final']>backtest['close']+threshold, 'Signal' ] =1\n",
        "backtest.loc[backtest['predictions_final']+threshold<backtest['close'], 'Signal' ] =-1\n",
        "backtest = backtest.rename(columns=lambda x: x.capitalize())\n",
        "backtest = backtest[:-1].copy()\n",
        "\n",
        "backtest = backtest.set_index('Time')\n",
        "\n",
        "\n",
        "class SignalStrategy(Strategy):\n",
        "    def init(self):\n",
        "        self.signal = self.I(lambda x: x, self.data['Signal'])\n",
        "        self.rsi = self.I(lambda x: x, self.data['Rsi'])\n",
        "\n",
        "    def next(self):\n",
        "        if self.signal[-1] == 1 and self.rsi[-1] >=50:\n",
        "            if not self.position or self.position.is_short:\n",
        "                if self.position:\n",
        "                    self.position.close()\n",
        "                self.buy()\n",
        "\n",
        "        elif self.signal[-1] == -1 and self.rsi[-1] <50:\n",
        "            if not self.position or self.position.is_long:\n",
        "                if self.position:\n",
        "                    self.position.close()\n",
        "                self.sell()\n",
        "\n",
        "\n",
        "# Create a backtest and run it\n",
        "btest = Backtest(backtest, SignalStrategy, cash=100000)\n",
        "stats = btest.run()\n",
        "\n",
        "print(stats)\n",
        "\n",
        "btest.plot(superimpose=False)\n"
      ],
      "metadata": {
        "id": "0yo_9HkUxNSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats = bt.run()\n",
        "\n",
        "print(stats)"
      ],
      "metadata": {
        "id": "dOlJTvv2bHyi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}